{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp100_8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1q27_3f4aulDvYJB1TGQWCyDlfmdTZC1Z",
      "authorship_tag": "ABX9TyN1cNI316rA3KpLSA7JKBO6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Young-Dong/nlp/blob/main/nlp100_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "第8章: ニューラルネット\n",
        "\n",
        "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．"
      ],
      "metadata": {
        "id": "9s2nJWBMnjR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
        "\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "with zipfile.ZipFile('NewsAggregatorDataset.zip') as f:\n",
        "    f.extractall('data')\n",
        "\n",
        "df = pd.read_csv('data/newsCorpora.csv', sep='\\t'\n",
        "   ,header=None, names=['ID','TITLE','URL','PUBLISHER','CATEGORY','STORY','HOSTNAME','TIMESTAMP'])\n",
        "target = ['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']\n",
        "df_target = df[df['PUBLISHER'].isin(target)]"
      ],
      "metadata": {
        "id": "uPfNfzkg50pX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b87cb1-8cb8-4c50-8656-378d234aa0c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-27 11:07:13--  https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29224203 (28M) [application/x-httpd-php]\n",
            "Saving to: ‘NewsAggregatorDataset.zip’\n",
            "\n",
            "NewsAggregatorDatas 100%[===================>]  27.87M  33.6MB/s    in 0.8s    \n",
            "\n",
            "2022-01-27 11:07:14 (33.6 MB/s) - ‘NewsAggregatorDataset.zip’ saved [29224203/29224203]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_target.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "0Xg0OFv_SbKd",
        "outputId": "b4ed4bde-6421-489c-8630-e1c8ab579b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-584ff752-c951-4e61-89b7-c02b99ddc52b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>URL</th>\n",
              "      <th>PUBLISHER</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>STORY</th>\n",
              "      <th>HOSTNAME</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>Europe reaches crunch point on banking union</td>\n",
              "      <td>http://in.reuters.com/article/2014/03/10/eu-ba...</td>\n",
              "      <td>Reuters</td>\n",
              "      <td>b</td>\n",
              "      <td>dPhGU51DcrolUIMxbRm0InaHGA2XM</td>\n",
              "      <td>in.reuters.com</td>\n",
              "      <td>1394470501755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>ECB FOCUS-Stronger euro drowns out ECB's messa...</td>\n",
              "      <td>http://in.reuters.com/article/2014/03/10/ecb-p...</td>\n",
              "      <td>Reuters</td>\n",
              "      <td>b</td>\n",
              "      <td>dPhGU51DcrolUIMxbRm0InaHGA2XM</td>\n",
              "      <td>in.reuters.com</td>\n",
              "      <td>1394470501948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>Euro Anxieties Wane as Bunds Top Treasuries, S...</td>\n",
              "      <td>http://www.businessweek.com/news/2014-03-10/ge...</td>\n",
              "      <td>Businessweek</td>\n",
              "      <td>b</td>\n",
              "      <td>dPhGU51DcrolUIMxbRm0InaHGA2XM</td>\n",
              "      <td>www.businessweek.com</td>\n",
              "      <td>1394470503148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>Noyer Says Strong Euro Creates Unwarranted Eco...</td>\n",
              "      <td>http://www.businessweek.com/news/2014-03-10/no...</td>\n",
              "      <td>Businessweek</td>\n",
              "      <td>b</td>\n",
              "      <td>dPhGU51DcrolUIMxbRm0InaHGA2XM</td>\n",
              "      <td>www.businessweek.com</td>\n",
              "      <td>1394470503366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>REFILE-Bad loan triggers key feature in ECB ba...</td>\n",
              "      <td>http://in.reuters.com/article/2014/03/10/euroz...</td>\n",
              "      <td>Reuters</td>\n",
              "      <td>b</td>\n",
              "      <td>dPhGU51DcrolUIMxbRm0InaHGA2XM</td>\n",
              "      <td>in.reuters.com</td>\n",
              "      <td>1394470505070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-584ff752-c951-4e61-89b7-c02b99ddc52b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-584ff752-c951-4e61-89b7-c02b99ddc52b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-584ff752-c951-4e61-89b7-c02b99ddc52b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    ID  ...      TIMESTAMP\n",
              "12  13  ...  1394470501755\n",
              "13  14  ...  1394470501948\n",
              "19  20  ...  1394470503148\n",
              "20  21  ...  1394470503366\n",
              "29  30  ...  1394470505070\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**70. 単語ベクトルの和による特徴量**\n",
        "\n",
        "問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．例えば，学習データについて，すべての事例$x_i$の特徴ベクトル$x_i$を並べた行列Xと，正解ラベルを並べた行列（ベクトル）Yを作成したい．\n",
        "\n",
        "> $\n",
        "X=\n",
        "\\left(\n",
        "\\begin{array}{c} \n",
        "    x_1\\\\ x_2\\\\ ...\\\\ x_n\\\\\n",
        "\\end{array}\n",
        "\\right)\n",
        "∈R^{n×d},\n",
        "Y=\n",
        "\\left(\n",
        "\\begin{array}{c} \n",
        "    y_1\\\\ y_2\\\\ ...\\\\ y_n\\\\\n",
        "\\end{array}\n",
        "\\right)\n",
        "∈N^{n}\n",
        "$\n",
        "\n",
        "ここで，nは学習データの事例数であり，$x_i$∈$R^d$と$y_i$∈Nはそれぞれ，i∈{1,…,n}番目の事例の特徴量ベクトルと正解ラベルを表す． なお，今回は「ビジネス」「科学技術」「エンターテイメント」「健康」の4カテゴリ分類である．N<4で4未満の自然数（0を含む）を表すことにすれば，任意の事例の正解ラベル$y_i$は$y_i$∈N<4で表現できる． 以降では，ラベルの種類数をLで表す（今回の分類タスクではL=4である）．\n",
        "\n",
        "i番目の事例の特徴ベクトル$x_i$は，次式で求める．\n",
        "\n",
        "> $x_i=\\frac{1}{T_i}∑_{t=1}^{T_i}emb(w_i,t)$\n",
        "\n",
        "ここで，i番目の事例は$T_i$個の（記事見出しの）単語列($w_{i,1},w_{i,2},…,w_{i,Ti}$)から構成され，emb(w)∈$R^d$は単語wに対応する単語ベクトル（次元数はd）である．すなわち，i番目の事例の記事見出しを，その見出しに含まれる単語のベクトルの平均で表現したものが$x_i$である．今回は単語ベクトルとして，問題60でダウンロードしたものを用いればよい．300次元の単語ベクトルを用いたので，d=300である．\n",
        "\n",
        "i番目の事例のラベル$y_i$は，次のように定義する．\n",
        "\n",
        "> $\n",
        "y_i=\\begin{cases}\n",
        "  {0 (記事x_iが「ビジネス」カテゴリの場合)\\\\\n",
        "  1 (記事x_iが「科学技術」カテゴリの場合)\\\\\n",
        "  2 (記事x_iが「エンターテイメント」カテゴリの場合)\\\\\n",
        "  3 (記事x_iが「健康」カテゴリの場合)}\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "なお，カテゴリ名とラベルの番号が一対一で対応付いていれば，上式の通りの対応付けでなくてもよい．\n",
        "\n",
        "以上の仕様に基づき，以下の行列・ベクトルを作成し，ファイルに保存せよ．\n",
        "\n",
        "・学習データの特徴量行列: $X_{train}∈R^{Nt×d}$\n",
        "\n",
        "・学習データのラベルベクトル: $Y_{train}∈N^{Nt}$\n",
        "\n",
        "・検証データの特徴量行列: $X_{valid}∈R^{Nv×d}$\n",
        "\n",
        "・検証データのラベルベクトル: $Y_{valid}∈N^{Nv}$\n",
        "\n",
        "・評価データの特徴量行列: $X_{test}∈R^{Ne×d}$\n",
        "\n",
        "・評価データのラベルベクトル: $Y_{test}∈N^{Ne}$\n",
        "\n",
        "なお，$N_t,N_v,N_e$はそれぞれ，学習データの事例数，検証データの事例数，評価データの事例数である．"
      ],
      "metadata": {
        "id": "RwBpYmMNr4zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, non_train = train_test_split(df_target, test_size=0.2, random_state=42)\n",
        "valid, test = train_test_split(non_train, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "oxl9v1-pXWzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from gensim.models import word2vec\n",
        "\n",
        "# official document https://radimrehurek.com/gensim/auto_examples/index.html#documentation\n",
        "\n",
        "data = '/content/drive/MyDrive/Colab Notebooks/GoogleNews-vectors-negative300.bin.gz'\n",
        "model = KeyedVectors.load_word2vec_format(data, binary=True)"
      ],
      "metadata": {
        "id": "Iw__AH5KXeVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import torch\n",
        "\n",
        "def transform_w2v(text):\n",
        "  table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "  words = text.translate(table).split()  # 記号をスペースに置換後、スペースで分割してリスト化\n",
        "  vec = [model[word] for word in words if word in model]  # 1語ずつベクトル化\n",
        "\n",
        "  return torch.tensor(sum(vec) / len(vec))  # 平均ベクトルをTensor型に変換して出力"
      ],
      "metadata": {
        "id": "ud0EuTj-YntT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴ベクトルの作成\n",
        "X_train = torch.stack([transform_w2v(text) for text in train['TITLE']])\n",
        "X_valid = torch.stack([transform_w2v(text) for text in valid['TITLE']])\n",
        "X_test = torch.stack([transform_w2v(text) for text in test['TITLE']])\n",
        "\n",
        "print(X_train.size())\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wgWWwsMYqN2",
        "outputId": "64de31bd-1696-43e7-d00c-204c4e1395be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10672, 300])\n",
            "tensor([[ 0.0892, -0.0251, -0.0682,  ..., -0.0559, -0.0038, -0.0919],\n",
            "        [ 0.0538,  0.0353,  0.0121,  ...,  0.1317,  0.2012,  0.0249],\n",
            "        [ 0.1075,  0.0263, -0.0342,  ...,  0.0381,  0.0845,  0.0992],\n",
            "        ...,\n",
            "        [ 0.0018,  0.0506,  0.0403,  ..., -0.0771,  0.0192, -0.0621],\n",
            "        [-0.0252,  0.0566, -0.0808,  ...,  0.0292,  0.0887,  0.0360],\n",
            "        [-0.0016,  0.1155, -0.0469,  ...,  0.0594, -0.0317, -0.1071]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ラベルベクトルの作成\n",
        "category_dict = {'b': 0, 't': 1, 'e': 2, 'm': 3}\n",
        "y_train = torch.LongTensor([category_dict[x] for x in train['CATEGORY']])\n",
        "y_valid = torch.LongTensor([category_dict[x] for x in valid['CATEGORY']])\n",
        "y_test = torch.LongTensor([category_dict[x] for x in test['CATEGORY']])\n",
        "\n",
        "print(y_train.size())\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "sSS3B_UeT67P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c7c3e4-47a1-4d63-9684-58382c103b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10672])\n",
            "tensor([0, 3, 2,  ..., 2, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存\n",
        "torch.save(X_train, 'X_train.pt')\n",
        "torch.save(X_valid, 'X_valid.pt')\n",
        "torch.save(X_test, 'X_test.pt')\n",
        "torch.save(y_train, 'y_train.pt')\n",
        "torch.save(y_valid, 'y_valid.pt')\n",
        "torch.save(y_test, 'y_test.pt')"
      ],
      "metadata": {
        "id": "hnsp3ESOaXjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**71. 単層ニューラルネットワークによる予測**\n",
        "\n",
        "問題70で保存した行列を読み込み，学習データについて以下の計算を実行せよ．\n",
        "\n",
        "$y_1=softmax(x_1W),Y=softmax(X_{[1:4]}W)$\n",
        "\n",
        "ただし，softmaxはソフトマックス関数，X[1:4]∈R4×dは特徴ベクトルx1,x2,x3,x4を縦に並べた行列である．\n",
        "\n",
        "\n",
        "\n",
        "> $\n",
        "X_{[1:4]}=\n",
        "\\left(\n",
        "\\begin{array}{c} \n",
        "    x_1\\\\ x_2\\\\ x_3\\\\ x_4\\\\\n",
        "\\end{array}\n",
        "\\right)\n",
        "$\n",
        "\n",
        "行列$W∈R^{d×L}$は単層ニューラルネットワークの重み行列で，ここではランダムな値で初期化すればよい（問題73以降で学習して求める）．なお，$y_1∈R^L$は未学習の行列Wで事例$x_1$を分類したときに，各カテゴリに属する確率を表すベクトルである． 同様に，$Y∈R^{n×L}$は，学習データの事例$x_1,x_2,x_3,x_4$について，各カテゴリに属する確率を行列として表現している．"
      ],
      "metadata": {
        "id": "0orfKthQ8BQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "m = nn.Linear(300, 4)"
      ],
      "metadata": {
        "id": "fkSAgweNPXKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.forward(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edDRR_tQfbzs",
        "outputId": "de86baae-b731-4811-e422-51a86b00c417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0866,  0.0092,  0.0851,  0.0258],\n",
              "        [-0.0129, -0.0249,  0.1280,  0.0317],\n",
              "        [-0.0566,  0.0274,  0.0046,  0.0176],\n",
              "        ...,\n",
              "        [-0.0281, -0.0380,  0.0823,  0.0281],\n",
              "        [-0.0335, -0.0066,  0.1265,  0.0348],\n",
              "        [-0.0622,  0.0037,  0.0909,  0.1341]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = torch.softmax(m.forward(X_train[:4]), dim=1)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mPVxSdN76vu",
        "outputId": "6a0fa5aa-4814-426b-d803-de67facdc1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7322, 0.0242, 0.2265, 0.0171],\n",
              "        [0.2979, 0.0383, 0.6327, 0.0312],\n",
              "        [0.2879, 0.0461, 0.6345, 0.0314],\n",
              "        [0.4471, 0.0289, 0.5040, 0.0200]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**72. 損失と勾配の計算**\n",
        "\n",
        "学習データの事例$x_1$と事例集合$x_1,x_2,x_3,x_4$に対して，クロスエントロピー損失と，行列Wに対する勾配を計算せよ．なお，ある事例$x_i$に対して損失は次式で計算される．\n",
        "\n",
        "> $l_i=−log[事例x_iがy_iに分類される確率]$\n",
        "\n",
        "ただし，事例集合に対するクロスエントロピー損失は，その集合に含まれる各事例の損失の平均とする．"
      ],
      "metadata": {
        "id": "USND8r928BTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "uhiqS72m7dR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = loss(m(X_train[:1]), y_train[:1])  # 入力ベクトルはsoftmax前の値\n",
        "# m.zero_grad()  # 勾配をゼロで初期化\n",
        "l1.backward()  # 勾配を計算\n",
        "print(f'損失: {l1:.4f}')\n",
        "print(f'勾配: {m.weight.grad}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jos6YoeIG_hP",
        "outputId": "5339e7ca-cddc-49ca-ae61-dab538333c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "損失: 1.3754\n",
            "勾配: tensor([[-0.0642,  0.0151,  0.0538,  ...,  0.0326, -0.0082,  0.0798],\n",
            "        [ 0.0225, -0.0022, -0.0217,  ..., -0.0133,  0.0069, -0.0223],\n",
            "        [ 0.0168, -0.0121, -0.0093,  ..., -0.0043, -0.0042, -0.0323],\n",
            "        [ 0.0249, -0.0008, -0.0229,  ..., -0.0150,  0.0054, -0.0252]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**73. 確率的勾配降下法による学習**\n",
        "\n",
        "確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列Wを学習せよ．なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）．"
      ],
      "metadata": {
        "id": "0I8c8Bvt8BWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(m.parameters(), lr=0.1)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  m.train()\n",
        "\n",
        "  y_train_pred = torch.softmax(m.forward(X_train), dim=1)\n",
        "  y_valid_pred = torch.softmax(m.forward(X_valid), dim=1)\n",
        "\n",
        "  loss_train = loss(y_train_pred, y_train)\n",
        "  loss_valid = loss(y_valid_pred, y_valid)\n",
        "\n",
        "  loss_train.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, loss_valid: {loss_valid:.4f}')"
      ],
      "metadata": {
        "id": "58kAEq5MI5fD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a494e1-dc98-4402-de65-ea16dd14bc93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss_train: 1.0634, loss_valid: 1.0782\n",
            "epoch: 2, loss_train: 1.0632, loss_valid: 1.0781\n",
            "epoch: 3, loss_train: 1.0630, loss_valid: 1.0779\n",
            "epoch: 4, loss_train: 1.0629, loss_valid: 1.0778\n",
            "epoch: 5, loss_train: 1.0627, loss_valid: 1.0776\n",
            "epoch: 6, loss_train: 1.0625, loss_valid: 1.0774\n",
            "epoch: 7, loss_train: 1.0624, loss_valid: 1.0773\n",
            "epoch: 8, loss_train: 1.0622, loss_valid: 1.0771\n",
            "epoch: 9, loss_train: 1.0621, loss_valid: 1.0770\n",
            "epoch: 10, loss_train: 1.0619, loss_valid: 1.0768\n",
            "epoch: 11, loss_train: 1.0617, loss_valid: 1.0767\n",
            "epoch: 12, loss_train: 1.0616, loss_valid: 1.0765\n",
            "epoch: 13, loss_train: 1.0614, loss_valid: 1.0764\n",
            "epoch: 14, loss_train: 1.0613, loss_valid: 1.0762\n",
            "epoch: 15, loss_train: 1.0611, loss_valid: 1.0761\n",
            "epoch: 16, loss_train: 1.0610, loss_valid: 1.0759\n",
            "epoch: 17, loss_train: 1.0608, loss_valid: 1.0758\n",
            "epoch: 18, loss_train: 1.0607, loss_valid: 1.0756\n",
            "epoch: 19, loss_train: 1.0605, loss_valid: 1.0755\n",
            "epoch: 20, loss_train: 1.0604, loss_valid: 1.0753\n",
            "epoch: 21, loss_train: 1.0602, loss_valid: 1.0752\n",
            "epoch: 22, loss_train: 1.0600, loss_valid: 1.0750\n",
            "epoch: 23, loss_train: 1.0599, loss_valid: 1.0749\n",
            "epoch: 24, loss_train: 1.0597, loss_valid: 1.0747\n",
            "epoch: 25, loss_train: 1.0596, loss_valid: 1.0746\n",
            "epoch: 26, loss_train: 1.0594, loss_valid: 1.0744\n",
            "epoch: 27, loss_train: 1.0593, loss_valid: 1.0743\n",
            "epoch: 28, loss_train: 1.0591, loss_valid: 1.0742\n",
            "epoch: 29, loss_train: 1.0590, loss_valid: 1.0740\n",
            "epoch: 30, loss_train: 1.0588, loss_valid: 1.0739\n",
            "epoch: 31, loss_train: 1.0587, loss_valid: 1.0737\n",
            "epoch: 32, loss_train: 1.0585, loss_valid: 1.0736\n",
            "epoch: 33, loss_train: 1.0584, loss_valid: 1.0734\n",
            "epoch: 34, loss_train: 1.0583, loss_valid: 1.0733\n",
            "epoch: 35, loss_train: 1.0581, loss_valid: 1.0732\n",
            "epoch: 36, loss_train: 1.0580, loss_valid: 1.0730\n",
            "epoch: 37, loss_train: 1.0578, loss_valid: 1.0729\n",
            "epoch: 38, loss_train: 1.0577, loss_valid: 1.0727\n",
            "epoch: 39, loss_train: 1.0575, loss_valid: 1.0726\n",
            "epoch: 40, loss_train: 1.0574, loss_valid: 1.0725\n",
            "epoch: 41, loss_train: 1.0572, loss_valid: 1.0723\n",
            "epoch: 42, loss_train: 1.0571, loss_valid: 1.0722\n",
            "epoch: 43, loss_train: 1.0570, loss_valid: 1.0720\n",
            "epoch: 44, loss_train: 1.0568, loss_valid: 1.0719\n",
            "epoch: 45, loss_train: 1.0567, loss_valid: 1.0718\n",
            "epoch: 46, loss_train: 1.0565, loss_valid: 1.0716\n",
            "epoch: 47, loss_train: 1.0564, loss_valid: 1.0715\n",
            "epoch: 48, loss_train: 1.0562, loss_valid: 1.0714\n",
            "epoch: 49, loss_train: 1.0561, loss_valid: 1.0712\n",
            "epoch: 50, loss_train: 1.0560, loss_valid: 1.0711\n",
            "epoch: 51, loss_train: 1.0558, loss_valid: 1.0710\n",
            "epoch: 52, loss_train: 1.0557, loss_valid: 1.0708\n",
            "epoch: 53, loss_train: 1.0556, loss_valid: 1.0707\n",
            "epoch: 54, loss_train: 1.0554, loss_valid: 1.0706\n",
            "epoch: 55, loss_train: 1.0553, loss_valid: 1.0704\n",
            "epoch: 56, loss_train: 1.0551, loss_valid: 1.0703\n",
            "epoch: 57, loss_train: 1.0550, loss_valid: 1.0702\n",
            "epoch: 58, loss_train: 1.0549, loss_valid: 1.0700\n",
            "epoch: 59, loss_train: 1.0547, loss_valid: 1.0699\n",
            "epoch: 60, loss_train: 1.0546, loss_valid: 1.0698\n",
            "epoch: 61, loss_train: 1.0545, loss_valid: 1.0696\n",
            "epoch: 62, loss_train: 1.0543, loss_valid: 1.0695\n",
            "epoch: 63, loss_train: 1.0542, loss_valid: 1.0694\n",
            "epoch: 64, loss_train: 1.0541, loss_valid: 1.0693\n",
            "epoch: 65, loss_train: 1.0539, loss_valid: 1.0691\n",
            "epoch: 66, loss_train: 1.0538, loss_valid: 1.0690\n",
            "epoch: 67, loss_train: 1.0537, loss_valid: 1.0689\n",
            "epoch: 68, loss_train: 1.0535, loss_valid: 1.0687\n",
            "epoch: 69, loss_train: 1.0534, loss_valid: 1.0686\n",
            "epoch: 70, loss_train: 1.0533, loss_valid: 1.0685\n",
            "epoch: 71, loss_train: 1.0531, loss_valid: 1.0684\n",
            "epoch: 72, loss_train: 1.0530, loss_valid: 1.0682\n",
            "epoch: 73, loss_train: 1.0529, loss_valid: 1.0681\n",
            "epoch: 74, loss_train: 1.0527, loss_valid: 1.0680\n",
            "epoch: 75, loss_train: 1.0526, loss_valid: 1.0679\n",
            "epoch: 76, loss_train: 1.0525, loss_valid: 1.0677\n",
            "epoch: 77, loss_train: 1.0524, loss_valid: 1.0676\n",
            "epoch: 78, loss_train: 1.0522, loss_valid: 1.0675\n",
            "epoch: 79, loss_train: 1.0521, loss_valid: 1.0674\n",
            "epoch: 80, loss_train: 1.0520, loss_valid: 1.0672\n",
            "epoch: 81, loss_train: 1.0518, loss_valid: 1.0671\n",
            "epoch: 82, loss_train: 1.0517, loss_valid: 1.0670\n",
            "epoch: 83, loss_train: 1.0516, loss_valid: 1.0669\n",
            "epoch: 84, loss_train: 1.0515, loss_valid: 1.0667\n",
            "epoch: 85, loss_train: 1.0513, loss_valid: 1.0666\n",
            "epoch: 86, loss_train: 1.0512, loss_valid: 1.0665\n",
            "epoch: 87, loss_train: 1.0511, loss_valid: 1.0664\n",
            "epoch: 88, loss_train: 1.0510, loss_valid: 1.0663\n",
            "epoch: 89, loss_train: 1.0508, loss_valid: 1.0661\n",
            "epoch: 90, loss_train: 1.0507, loss_valid: 1.0660\n",
            "epoch: 91, loss_train: 1.0506, loss_valid: 1.0659\n",
            "epoch: 92, loss_train: 1.0505, loss_valid: 1.0658\n",
            "epoch: 93, loss_train: 1.0503, loss_valid: 1.0657\n",
            "epoch: 94, loss_train: 1.0502, loss_valid: 1.0655\n",
            "epoch: 95, loss_train: 1.0501, loss_valid: 1.0654\n",
            "epoch: 96, loss_train: 1.0500, loss_valid: 1.0653\n",
            "epoch: 97, loss_train: 1.0499, loss_valid: 1.0652\n",
            "epoch: 98, loss_train: 1.0497, loss_valid: 1.0651\n",
            "epoch: 99, loss_train: 1.0496, loss_valid: 1.0650\n",
            "epoch: 100, loss_train: 1.0495, loss_valid: 1.0648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**74. 正解率の計測**\n",
        "\n",
        "問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ．"
      ],
      "metadata": {
        "id": "JcotgOiK8BZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def acc(pred, y):\n",
        "  pred = torch.max(pred.data,1)[1]\n",
        "  return (pred == y).sum().item() / len(y)"
      ],
      "metadata": {
        "id": "9kQRUTGul4ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解率の確認\n",
        "acc_train = acc(y_train_pred, y_train)\n",
        "acc_valid = acc(y_valid_pred, y_valid)\n",
        "print(f'正解率（学習データ）：{acc_train:.3f}')\n",
        "print(f'正解率（評価データ）：{acc_valid:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj_LgKPUdfVY",
        "outputId": "97b3a3d3-fc20-4b9c-d6f3-22ecfa356574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正解率（学習データ）：0.782\n",
            "正解率（評価データ）：0.763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**75. 損失と正解率のプロット**\n",
        "\n",
        "問題73のコードを改変し，各エポックのパラメータ更新が完了するたびに，訓練データでの損失，正解率，検証データでの損失，正解率をグラフにプロットし，学習の進捗状況を確認できるようにせよ．"
      ],
      "metadata": {
        "id": "k2urfBD-8Bca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(m.parameters(), lr=0.1)\n",
        "\n",
        "num_epochs = 100\n",
        "log_train = []\n",
        "log_valid = []\n",
        "for epoch in range(num_epochs):\n",
        "  m.train()\n",
        "\n",
        "  y_train_pred = torch.softmax(m.forward(X_train), dim=1)\n",
        "  y_valid_pred = torch.softmax(m.forward(X_valid), dim=1)\n",
        "\n",
        "  loss_train = loss(y_train_pred, y_train)\n",
        "  loss_valid = loss(y_valid_pred, y_valid)\n",
        "\n",
        "  loss_train.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 正解率の算出\n",
        "  acc_train = acc(y_train_pred, y_train)\n",
        "  acc_valid = acc(y_valid_pred, y_valid)\n",
        "  log_train.append([loss_train, acc_train])\n",
        "  log_valid.append([loss_valid, acc_valid])\n",
        "\n",
        "  # ログを出力\n",
        "  print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_sdCG_bfTNv",
        "outputId": "c1178261-16d1-41f0-a9bb-242937a42cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss_train: 1.0305, accuracy_train: 0.7823, loss_valid: 1.0465, accuracy_valid: 0.7639\n",
            "epoch: 2, loss_train: 1.0304, accuracy_train: 0.7823, loss_valid: 1.0465, accuracy_valid: 0.7639\n",
            "epoch: 3, loss_train: 1.0303, accuracy_train: 0.7823, loss_valid: 1.0464, accuracy_valid: 0.7639\n",
            "epoch: 4, loss_train: 1.0302, accuracy_train: 0.7823, loss_valid: 1.0463, accuracy_valid: 0.7639\n",
            "epoch: 5, loss_train: 1.0302, accuracy_train: 0.7823, loss_valid: 1.0462, accuracy_valid: 0.7639\n",
            "epoch: 6, loss_train: 1.0301, accuracy_train: 0.7823, loss_valid: 1.0462, accuracy_valid: 0.7639\n",
            "epoch: 7, loss_train: 1.0300, accuracy_train: 0.7823, loss_valid: 1.0461, accuracy_valid: 0.7639\n",
            "epoch: 8, loss_train: 1.0299, accuracy_train: 0.7823, loss_valid: 1.0460, accuracy_valid: 0.7639\n",
            "epoch: 9, loss_train: 1.0299, accuracy_train: 0.7823, loss_valid: 1.0460, accuracy_valid: 0.7639\n",
            "epoch: 10, loss_train: 1.0298, accuracy_train: 0.7823, loss_valid: 1.0459, accuracy_valid: 0.7639\n",
            "epoch: 11, loss_train: 1.0297, accuracy_train: 0.7824, loss_valid: 1.0458, accuracy_valid: 0.7639\n",
            "epoch: 12, loss_train: 1.0297, accuracy_train: 0.7824, loss_valid: 1.0458, accuracy_valid: 0.7639\n",
            "epoch: 13, loss_train: 1.0296, accuracy_train: 0.7824, loss_valid: 1.0457, accuracy_valid: 0.7639\n",
            "epoch: 14, loss_train: 1.0295, accuracy_train: 0.7824, loss_valid: 1.0456, accuracy_valid: 0.7639\n",
            "epoch: 15, loss_train: 1.0294, accuracy_train: 0.7824, loss_valid: 1.0456, accuracy_valid: 0.7639\n",
            "epoch: 16, loss_train: 1.0294, accuracy_train: 0.7824, loss_valid: 1.0455, accuracy_valid: 0.7639\n",
            "epoch: 17, loss_train: 1.0293, accuracy_train: 0.7824, loss_valid: 1.0454, accuracy_valid: 0.7639\n",
            "epoch: 18, loss_train: 1.0292, accuracy_train: 0.7824, loss_valid: 1.0453, accuracy_valid: 0.7639\n",
            "epoch: 19, loss_train: 1.0292, accuracy_train: 0.7824, loss_valid: 1.0453, accuracy_valid: 0.7639\n",
            "epoch: 20, loss_train: 1.0291, accuracy_train: 0.7825, loss_valid: 1.0452, accuracy_valid: 0.7639\n",
            "epoch: 21, loss_train: 1.0290, accuracy_train: 0.7825, loss_valid: 1.0451, accuracy_valid: 0.7639\n",
            "epoch: 22, loss_train: 1.0289, accuracy_train: 0.7825, loss_valid: 1.0451, accuracy_valid: 0.7639\n",
            "epoch: 23, loss_train: 1.0289, accuracy_train: 0.7825, loss_valid: 1.0450, accuracy_valid: 0.7639\n",
            "epoch: 24, loss_train: 1.0288, accuracy_train: 0.7825, loss_valid: 1.0449, accuracy_valid: 0.7639\n",
            "epoch: 25, loss_train: 1.0287, accuracy_train: 0.7826, loss_valid: 1.0449, accuracy_valid: 0.7639\n",
            "epoch: 26, loss_train: 1.0287, accuracy_train: 0.7826, loss_valid: 1.0448, accuracy_valid: 0.7639\n",
            "epoch: 27, loss_train: 1.0286, accuracy_train: 0.7826, loss_valid: 1.0447, accuracy_valid: 0.7639\n",
            "epoch: 28, loss_train: 1.0285, accuracy_train: 0.7826, loss_valid: 1.0447, accuracy_valid: 0.7639\n",
            "epoch: 29, loss_train: 1.0284, accuracy_train: 0.7826, loss_valid: 1.0446, accuracy_valid: 0.7639\n",
            "epoch: 30, loss_train: 1.0284, accuracy_train: 0.7826, loss_valid: 1.0445, accuracy_valid: 0.7639\n",
            "epoch: 31, loss_train: 1.0283, accuracy_train: 0.7826, loss_valid: 1.0445, accuracy_valid: 0.7639\n",
            "epoch: 32, loss_train: 1.0282, accuracy_train: 0.7826, loss_valid: 1.0444, accuracy_valid: 0.7639\n",
            "epoch: 33, loss_train: 1.0282, accuracy_train: 0.7826, loss_valid: 1.0443, accuracy_valid: 0.7639\n",
            "epoch: 34, loss_train: 1.0281, accuracy_train: 0.7826, loss_valid: 1.0443, accuracy_valid: 0.7639\n",
            "epoch: 35, loss_train: 1.0280, accuracy_train: 0.7826, loss_valid: 1.0442, accuracy_valid: 0.7639\n",
            "epoch: 36, loss_train: 1.0280, accuracy_train: 0.7826, loss_valid: 1.0441, accuracy_valid: 0.7639\n",
            "epoch: 37, loss_train: 1.0279, accuracy_train: 0.7826, loss_valid: 1.0441, accuracy_valid: 0.7639\n",
            "epoch: 38, loss_train: 1.0278, accuracy_train: 0.7826, loss_valid: 1.0440, accuracy_valid: 0.7639\n",
            "epoch: 39, loss_train: 1.0278, accuracy_train: 0.7826, loss_valid: 1.0439, accuracy_valid: 0.7639\n",
            "epoch: 40, loss_train: 1.0277, accuracy_train: 0.7826, loss_valid: 1.0439, accuracy_valid: 0.7639\n",
            "epoch: 41, loss_train: 1.0276, accuracy_train: 0.7826, loss_valid: 1.0438, accuracy_valid: 0.7639\n",
            "epoch: 42, loss_train: 1.0276, accuracy_train: 0.7826, loss_valid: 1.0437, accuracy_valid: 0.7639\n",
            "epoch: 43, loss_train: 1.0275, accuracy_train: 0.7826, loss_valid: 1.0437, accuracy_valid: 0.7639\n",
            "epoch: 44, loss_train: 1.0274, accuracy_train: 0.7826, loss_valid: 1.0436, accuracy_valid: 0.7639\n",
            "epoch: 45, loss_train: 1.0274, accuracy_train: 0.7826, loss_valid: 1.0436, accuracy_valid: 0.7639\n",
            "epoch: 46, loss_train: 1.0273, accuracy_train: 0.7826, loss_valid: 1.0435, accuracy_valid: 0.7639\n",
            "epoch: 47, loss_train: 1.0272, accuracy_train: 0.7826, loss_valid: 1.0434, accuracy_valid: 0.7639\n",
            "epoch: 48, loss_train: 1.0272, accuracy_train: 0.7826, loss_valid: 1.0434, accuracy_valid: 0.7639\n",
            "epoch: 49, loss_train: 1.0271, accuracy_train: 0.7826, loss_valid: 1.0433, accuracy_valid: 0.7639\n",
            "epoch: 50, loss_train: 1.0270, accuracy_train: 0.7826, loss_valid: 1.0432, accuracy_valid: 0.7639\n",
            "epoch: 51, loss_train: 1.0270, accuracy_train: 0.7826, loss_valid: 1.0432, accuracy_valid: 0.7639\n",
            "epoch: 52, loss_train: 1.0269, accuracy_train: 0.7826, loss_valid: 1.0431, accuracy_valid: 0.7639\n",
            "epoch: 53, loss_train: 1.0268, accuracy_train: 0.7826, loss_valid: 1.0430, accuracy_valid: 0.7639\n",
            "epoch: 54, loss_train: 1.0268, accuracy_train: 0.7826, loss_valid: 1.0430, accuracy_valid: 0.7639\n",
            "epoch: 55, loss_train: 1.0267, accuracy_train: 0.7826, loss_valid: 1.0429, accuracy_valid: 0.7639\n",
            "epoch: 56, loss_train: 1.0266, accuracy_train: 0.7826, loss_valid: 1.0429, accuracy_valid: 0.7639\n",
            "epoch: 57, loss_train: 1.0266, accuracy_train: 0.7826, loss_valid: 1.0428, accuracy_valid: 0.7639\n",
            "epoch: 58, loss_train: 1.0265, accuracy_train: 0.7826, loss_valid: 1.0427, accuracy_valid: 0.7639\n",
            "epoch: 59, loss_train: 1.0264, accuracy_train: 0.7827, loss_valid: 1.0427, accuracy_valid: 0.7639\n",
            "epoch: 60, loss_train: 1.0264, accuracy_train: 0.7827, loss_valid: 1.0426, accuracy_valid: 0.7639\n",
            "epoch: 61, loss_train: 1.0263, accuracy_train: 0.7827, loss_valid: 1.0425, accuracy_valid: 0.7639\n",
            "epoch: 62, loss_train: 1.0262, accuracy_train: 0.7827, loss_valid: 1.0425, accuracy_valid: 0.7639\n",
            "epoch: 63, loss_train: 1.0262, accuracy_train: 0.7828, loss_valid: 1.0424, accuracy_valid: 0.7639\n",
            "epoch: 64, loss_train: 1.0261, accuracy_train: 0.7828, loss_valid: 1.0423, accuracy_valid: 0.7639\n",
            "epoch: 65, loss_train: 1.0260, accuracy_train: 0.7828, loss_valid: 1.0423, accuracy_valid: 0.7639\n",
            "epoch: 66, loss_train: 1.0260, accuracy_train: 0.7828, loss_valid: 1.0422, accuracy_valid: 0.7639\n",
            "epoch: 67, loss_train: 1.0259, accuracy_train: 0.7828, loss_valid: 1.0422, accuracy_valid: 0.7639\n",
            "epoch: 68, loss_train: 1.0258, accuracy_train: 0.7828, loss_valid: 1.0421, accuracy_valid: 0.7639\n",
            "epoch: 69, loss_train: 1.0258, accuracy_train: 0.7829, loss_valid: 1.0420, accuracy_valid: 0.7639\n",
            "epoch: 70, loss_train: 1.0257, accuracy_train: 0.7829, loss_valid: 1.0420, accuracy_valid: 0.7639\n",
            "epoch: 71, loss_train: 1.0256, accuracy_train: 0.7829, loss_valid: 1.0419, accuracy_valid: 0.7639\n",
            "epoch: 72, loss_train: 1.0256, accuracy_train: 0.7829, loss_valid: 1.0419, accuracy_valid: 0.7639\n",
            "epoch: 73, loss_train: 1.0255, accuracy_train: 0.7829, loss_valid: 1.0418, accuracy_valid: 0.7639\n",
            "epoch: 74, loss_train: 1.0255, accuracy_train: 0.7829, loss_valid: 1.0417, accuracy_valid: 0.7639\n",
            "epoch: 75, loss_train: 1.0254, accuracy_train: 0.7829, loss_valid: 1.0417, accuracy_valid: 0.7639\n",
            "epoch: 76, loss_train: 1.0253, accuracy_train: 0.7829, loss_valid: 1.0416, accuracy_valid: 0.7639\n",
            "epoch: 77, loss_train: 1.0253, accuracy_train: 0.7829, loss_valid: 1.0416, accuracy_valid: 0.7639\n",
            "epoch: 78, loss_train: 1.0252, accuracy_train: 0.7829, loss_valid: 1.0415, accuracy_valid: 0.7639\n",
            "epoch: 79, loss_train: 1.0251, accuracy_train: 0.7829, loss_valid: 1.0414, accuracy_valid: 0.7639\n",
            "epoch: 80, loss_train: 1.0251, accuracy_train: 0.7829, loss_valid: 1.0414, accuracy_valid: 0.7639\n",
            "epoch: 81, loss_train: 1.0250, accuracy_train: 0.7829, loss_valid: 1.0413, accuracy_valid: 0.7639\n",
            "epoch: 82, loss_train: 1.0249, accuracy_train: 0.7829, loss_valid: 1.0413, accuracy_valid: 0.7639\n",
            "epoch: 83, loss_train: 1.0249, accuracy_train: 0.7829, loss_valid: 1.0412, accuracy_valid: 0.7639\n",
            "epoch: 84, loss_train: 1.0248, accuracy_train: 0.7829, loss_valid: 1.0411, accuracy_valid: 0.7639\n",
            "epoch: 85, loss_train: 1.0248, accuracy_train: 0.7829, loss_valid: 1.0411, accuracy_valid: 0.7639\n",
            "epoch: 86, loss_train: 1.0247, accuracy_train: 0.7829, loss_valid: 1.0410, accuracy_valid: 0.7639\n",
            "epoch: 87, loss_train: 1.0246, accuracy_train: 0.7829, loss_valid: 1.0410, accuracy_valid: 0.7639\n",
            "epoch: 88, loss_train: 1.0246, accuracy_train: 0.7829, loss_valid: 1.0409, accuracy_valid: 0.7639\n",
            "epoch: 89, loss_train: 1.0245, accuracy_train: 0.7829, loss_valid: 1.0408, accuracy_valid: 0.7639\n",
            "epoch: 90, loss_train: 1.0245, accuracy_train: 0.7829, loss_valid: 1.0408, accuracy_valid: 0.7639\n",
            "epoch: 91, loss_train: 1.0244, accuracy_train: 0.7829, loss_valid: 1.0407, accuracy_valid: 0.7639\n",
            "epoch: 92, loss_train: 1.0243, accuracy_train: 0.7829, loss_valid: 1.0407, accuracy_valid: 0.7639\n",
            "epoch: 93, loss_train: 1.0243, accuracy_train: 0.7829, loss_valid: 1.0406, accuracy_valid: 0.7639\n",
            "epoch: 94, loss_train: 1.0242, accuracy_train: 0.7829, loss_valid: 1.0405, accuracy_valid: 0.7639\n",
            "epoch: 95, loss_train: 1.0241, accuracy_train: 0.7829, loss_valid: 1.0405, accuracy_valid: 0.7639\n",
            "epoch: 96, loss_train: 1.0241, accuracy_train: 0.7829, loss_valid: 1.0404, accuracy_valid: 0.7639\n",
            "epoch: 97, loss_train: 1.0240, accuracy_train: 0.7829, loss_valid: 1.0404, accuracy_valid: 0.7639\n",
            "epoch: 98, loss_train: 1.0240, accuracy_train: 0.7829, loss_valid: 1.0403, accuracy_valid: 0.7639\n",
            "epoch: 99, loss_train: 1.0239, accuracy_train: 0.7829, loss_valid: 1.0402, accuracy_valid: 0.7639\n",
            "epoch: 100, loss_train: 1.0238, accuracy_train: 0.7829, loss_valid: 1.0402, accuracy_valid: 0.7639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# 可視化\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "ax[0].plot(np.array(log_train).T[0], label='train')\n",
        "ax[0].plot(np.array(log_valid).T[0], label='valid')\n",
        "ax[0].set_xlabel('epoch')\n",
        "ax[0].set_ylabel('loss')\n",
        "ax[0].legend()\n",
        "ax[1].plot(np.array(log_train).T[1], label='train')\n",
        "ax[1].plot(np.array(log_valid).T[1], label='valid')\n",
        "ax[1].set_xlabel('epoch')\n",
        "ax[1].set_ylabel('accuracy')\n",
        "ax[1].legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "RDVkejDYwNk4",
        "outputId": "11944938-08f0-4299-db03-d1b061efc5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**76. チェックポイント**\n",
        "\n",
        "問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．"
      ],
      "metadata": {
        "id": "cGmPhuGj8Bfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**77. ミニバッチ化**\n",
        "\n",
        "問題76のコードを改変し，B事例ごとに損失・勾配を計算し，行列Wの値を更新せよ（ミニバッチ化）．Bの値を1,2,4,8,…と変化させながら，1エポックの学習に要する時間を比較せよ．"
      ],
      "metadata": {
        "id": "2OQjhoDf8BiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**78. GPU上での学習**\n",
        "\n",
        "問題77のコードを改変し，GPU上で学習を実行せよ．"
      ],
      "metadata": {
        "id": "ky2OHFx_8Bky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**79. 多層ニューラルネットワーク**\n",
        "\n",
        "問題78のコードを改変し，バイアス項の導入や多層化など，ニューラルネットワークの形状を変更しながら，高性能なカテゴリ分類器を構築せよ．"
      ],
      "metadata": {
        "id": "Eb5aZqu8-j2p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvgZg88smrYj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}