{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp100_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyON/Q+Z8aMuZNgUKCPi/L3T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Young-Dong/nlp/blob/main/nlp100_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQjtnA93txoh"
      },
      "source": [
        "第6章: 機械学習\n",
        "\n",
        "本章では，Fabio Gasparetti氏が公開している[News Aggregator Data Set](https://archive.ics.uci.edu/ml/datasets/News+Aggregator)を用い，ニュース記事の見出しを「ビジネス」「科学技術」「エンターテイメント」「健康」のカテゴリに分類するタスク（カテゴリ分類）に取り組む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHNoiIpl5RTQ",
        "outputId": "a064e1bf-ecfa-4c23-f21a-92a4a0298aeb"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-09 12:43:26--  https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29224203 (28M) [application/x-httpd-php]\n",
            "Saving to: ‘NewsAggregatorDataset.zip’\n",
            "\n",
            "NewsAggregatorDatas 100%[===================>]  27.87M  33.2MB/s    in 0.8s    \n",
            "\n",
            "2021-12-09 12:43:27 (33.2 MB/s) - ‘NewsAggregatorDataset.zip’ saved [29224203/29224203]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVKRktbAvkhl"
      },
      "source": [
        "50. データの入手・整形\n",
        "\n",
        "News Aggregator Data Setをダウンロードし、以下の要領で学習データ（train.txt），検証データ（valid.txt），評価データ（test.txt）を作成せよ．\n",
        "\n",
        "1.ダウンロードしたzipファイルを解凍し，readme.txtの説明を読む．\n",
        "\n",
        "2.情報源（publisher）が”Reuters”, “Huffington Post”, “Businessweek”, “Contactmusic.com”, “Daily Mail”の事例（記事）のみを抽出する．\n",
        "\n",
        "3.抽出された事例をランダムに並び替える．\n",
        "\n",
        "4.抽出された事例の80%を学習データ，残りの10%ずつを検証データと評価データに分割し，それぞれtrain.txt，valid.txt，test.txtというファイル名で保存する．ファイルには，１行に１事例を書き出すこととし，カテゴリ名と記事見出しのタブ区切り形式とせよ（このファイルは後に問題70で再利用する）．\n",
        "学習データと評価データを作成したら，各カテゴリの事例数を確認せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUOUMFRhuie-",
        "outputId": "abb863e4-fc03-47dd-c7bb-3c6667933f6f"
      },
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "with zipfile.ZipFile('NewsAggregatorDataset.zip') as f:\n",
        "    f.extractall('data')\n",
        "\n",
        "with open('data/readme.txt') as f:\n",
        "  while True:\n",
        "    s_line = f.readline()\n",
        "    print(s_line)\n",
        "    if not s_line:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUMMARY: Dataset of references (urls) to news web pages\n",
            "\n",
            "\n",
            "\n",
            "DESCRIPTION: Dataset of references to news web pages collected from an online aggregator in the period from March 10 to August 10 of 2014. The resources are grouped into clusters that represent pages discussing the same news story. The dataset includes also references to web pages that point (has a link to) one of the news page in the collection.\n",
            "\n",
            "\n",
            "\n",
            "TAGS: web pages, news, aggregator, classification, clustering\n",
            "\n",
            "\n",
            "\n",
            "LICENSE: Public domain - Due to restrictions on content and use of the news sources, the corpus is limited to web references (urls) to web pages and does not include any text content. The references have been retrieved from the news aggregator through traditional web browsers. \n",
            "\n",
            "\n",
            "\n",
            "FILE ENCODING: UTF-8\n",
            "\n",
            "\n",
            "\n",
            "FORMAT: Tab delimited CSV files. \n",
            "\n",
            "\n",
            "\n",
            "DATA SHAPE AND STATS: 422937 news pages and divided up into:\n",
            "\n",
            "\n",
            "\n",
            "152746 \tnews of business category\n",
            "\n",
            "108465 \tnews of science and technology category\n",
            "\n",
            "115920 \tnews of business category\n",
            "\n",
            " 45615 \tnews of health category\n",
            "\n",
            "\n",
            "\n",
            "2076 clusters of similar news for entertainment category\n",
            "\n",
            "1789 clusters of similar news for science and technology category\n",
            "\n",
            "2019 clusters of similar news for business category\n",
            "\n",
            "1347 clusters of similar news for health category\n",
            "\n",
            "\n",
            "\n",
            "References to web pages containing a link to one news included in the collection are also included. They are represented as pairs of urls corresponding to 2-page browsing sessions. The collection includes 15516 2-page browsing sessions covering 946 distinct clusters divided up into:\n",
            "\n",
            "\n",
            "\n",
            "6091 2-page sessions for business category\n",
            "\n",
            "9425 2-page sessions for entertainment category\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "CONTENT\n",
            "\n",
            "=======\n",
            "\n",
            "\n",
            "\n",
            "FILENAME #1: newsCorpora.csv (102.297.000 bytes)\n",
            "\n",
            "DESCRIPTION: News pages\n",
            "\n",
            "FORMAT: ID \\t TITLE \\t URL \\t PUBLISHER \\t CATEGORY \\t STORY \\t HOSTNAME \\t TIMESTAMP\n",
            "\n",
            "\n",
            "\n",
            "where:\n",
            "\n",
            "ID\t\tNumeric ID\n",
            "\n",
            "TITLE\t\tNews title \n",
            "\n",
            "URL\t\tUrl\n",
            "\n",
            "PUBLISHER\tPublisher name\n",
            "\n",
            "CATEGORY\tNews category (b = business, t = science and technology, e = entertainment, m = health)\n",
            "\n",
            "STORY\t\tAlphanumeric ID of the cluster that includes news about the same story\n",
            "\n",
            "HOSTNAME\tUrl hostname\n",
            "\n",
            "TIMESTAMP \tApproximate time the news was published, as the number of milliseconds since the epoch 00:00:00 GMT, January 1, 1970\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "FILENAME #2: 2pageSessions.csv (3.049.986 bytes)\n",
            "\n",
            "DESCRIPTION: 2-page sessions\n",
            "\n",
            "FORMAT: STORY \\t HOSTNAME \\t CATEGORY \\t URL\n",
            "\n",
            "\n",
            "\n",
            "where:\n",
            "\n",
            "STORY\t\tAlphanumeric ID of the cluster that includes news about the same story\n",
            "\n",
            "HOSTNAME\tUrl hostname\n",
            "\n",
            "CATEGORY\tNews category (b = business, t = science and technology, e = entertainment, m = health)\n",
            "\n",
            "URL\t\tTwo space-delimited urls representing a browsing session\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "id": "IOHp-a5Ku3Mw",
        "outputId": "fe06273d-3a1b-41b8-8150-6eb1152b92be"
      },
      "source": [
        "df = pd.read_csv('data/newsCorpora.csv', sep='\\t'\n",
        "   ,header=None, names=['ID','TITLE','URL','PUBLISHER','CATEGORY','STORY','HOSTNAME','TIMESTAMP'])\n",
        "target = ['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']\n",
        "df_target = df[df['PUBLISHER'].isin(target)]\n",
        "print(df.shape,'\\n', df_target.shape)\n",
        "df_target.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(422419, 8) \n",
            " (13340, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>URL</th>\n",
              "      <th>PUBLISHER</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>STORY</th>\n",
              "      <th>HOSTNAME</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>Europe reaches crunch point on banking union</td>\n",
              "      <td>http://in.reuters.com/article/2014/03/10/eu-ba...</td>\n",
              "      <td>Reuters</td>\n",
              "      <td>b</td>\n",
              "      <td>dPhGU51DcrolUIMxbRm0InaHGA2XM</td>\n",
              "      <td>in.reuters.com</td>\n",
              "      <td>1394470501755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>ECB FOCUS-Stronger euro drowns out ECB's messa...</td>\n",
              "      <td>http://in.reuters.com/article/2014/03/10/ecb-p...</td>\n",
              "      <td>Reuters</td>\n",
              "      <td>b</td>\n",
              "      <td>dPhGU51DcrolUIMxbRm0InaHGA2XM</td>\n",
              "      <td>in.reuters.com</td>\n",
              "      <td>1394470501948</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ID  ...      TIMESTAMP\n",
              "12  13  ...  1394470501755\n",
              "13  14  ...  1394470501948\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "PWzDhe7IB7Mh",
        "outputId": "10be71d2-5c14-4ac6-c721-dde5a70459e5"
      },
      "source": [
        "# train_test_split can do this..\n",
        "from sklearn.utils import shuffle\n",
        "df_target = shuffle(df_target).reset_index().drop(columns='index')\n",
        "df_target.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>URL</th>\n",
              "      <th>PUBLISHER</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>STORY</th>\n",
              "      <th>HOSTNAME</th>\n",
              "      <th>TIMESTAMP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>387241</td>\n",
              "      <td>Time Warner Shareholders Call Murdoch Bid Hard...</td>\n",
              "      <td>http://www.businessweek.com/news/2014-07-16/ti...</td>\n",
              "      <td>Businessweek</td>\n",
              "      <td>b</td>\n",
              "      <td>dMElbuCt8WnYaeM7R5FNMSjx8irwM</td>\n",
              "      <td>www.businessweek.com</td>\n",
              "      <td>1405613266717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>88971</td>\n",
              "      <td>Neil Patrick Harris On Taking Over For David L...</td>\n",
              "      <td>http://www.huffingtonpost.com/2014/04/07/neil-...</td>\n",
              "      <td>Huffington Post</td>\n",
              "      <td>e</td>\n",
              "      <td>dynU_WiAg43028M4GORaVNmgsOgLM</td>\n",
              "      <td>www.huffingtonpost.com</td>\n",
              "      <td>1396935110392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID  ...      TIMESTAMP\n",
              "0  387241  ...  1405613266717\n",
              "1   88971  ...  1396935110392\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6TDjivHCAHr",
        "outputId": "11616c12-1ee2-4c63-e351-fd97f3ea3fcd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, non_train = train_test_split(df_target[['TITLE','CATEGORY']], test_size=0.2, random_state=42)\n",
        "valid, test = train_test_split(non_train, test_size=0.5, random_state=42)\n",
        "train.to_csv('train.txt', sep='\\t')\n",
        "valid.to_csv('valid.txt', sep='\\t')\n",
        "test.to_csv('test.txt', sep='\\t')\n",
        "print(train.shape, '\\n', valid.shape, '\\n', test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10672, 2) \n",
            " (1334, 2) \n",
            " (1334, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duR9Y1kQJLQj",
        "outputId": "f5fcfe3a-3744-4cc0-9909-2de659e87c9e"
      },
      "source": [
        "train['CATEGORY'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b    4546\n",
              "e    4178\n",
              "t    1209\n",
              "m     739\n",
              "Name: CATEGORY, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytIXANYbKI2t",
        "outputId": "58790627-4981-444f-f4b1-3abd35e4da5a"
      },
      "source": [
        "test['CATEGORY'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b    566\n",
              "e    531\n",
              "t    154\n",
              "m     83\n",
              "Name: CATEGORY, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21qY0wmbKOyS"
      },
      "source": [
        "51. 特徴量抽出\n",
        "\n",
        "学習データ，検証データ，評価データから特徴量を抽出し，それぞれtrain.feature.txt，valid.feature.txt，test.feature.txtというファイル名で保存せよ． なお，カテゴリ分類に有用そうな特徴量は各自で自由に設計せよ．記事の見出しを単語列に変換したものが最低限のベースラインとなるであろう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv1VMilsPixB",
        "outputId": "b771d63f-e46a-46cf-c78e-bb7b1376718f"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df_target['TITLE'])\n",
        "vectorizer.get_feature_names_out()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['00', '05', '07', ..., 'œlousyâ', 'œpiece', 'œwaist'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyQ-Pcz7GdJu",
        "outputId": "a4e01965-e08d-428e-ab23-5ed1bf394cff"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13340, 14039)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4Lp9JAuzdSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "142d5521-1c30-4823-e5fe-e1027b6c894c"
      },
      "source": [
        "y_train, y_non_train, X_train, X_non_train = train_test_split(df_target['CATEGORY'], X, test_size=0.2, random_state=42)\n",
        "y_valid, y_test, X_valid, X_test = train_test_split(y_non_train, X_non_train, test_size=0.5, random_state=42)\n",
        "pd.DataFrame(X_train).to_csv('train.feature.txt', sep='\\t')\n",
        "pd.DataFrame(X_valid).to_csv('valid.feature.txt', sep='\\t')\n",
        "pd.DataFrame(X_test).to_csv('test.feature.txt', sep='\\t')\n",
        "print(X_train.shape, '\\n', X_valid.shape, '\\n', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10672, 14039) \n",
            " (1334, 14039) \n",
            " (1334, 14039)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1-S9ifHcb7v"
      },
      "source": [
        "52. 学習\n",
        "\n",
        "51で構築した学習データを用いて，ロジスティック回帰モデルを学習せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Tl3yJAcbWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400eac98-de72-4f83-da63-6f67cde9e6a5"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(random_state=0)\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aSTaezHdSyH"
      },
      "source": [
        "53. 予測\n",
        "\n",
        "52で学習したロジスティック回帰モデルを用い，与えられた記事見出しからカテゴリとその予測確率を計算するプログラムを実装せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-gkMCzXdVJS"
      },
      "source": [
        "y_train_pred = lr.predict(X_train)\n",
        "y_test_pred = lr.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxzxHMEYeFXJ"
      },
      "source": [
        "54. 正解率の計測\n",
        "\n",
        "52で学習したロジスティック回帰モデルの正解率を，学習データおよび評価データ上で計測せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK4z3vkEeGxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9dacc6-d8b9-4020-9389-2324b74b4803"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print('train accuracy = ', accuracy_score(y_true=y_train, y_pred=y_train_pred))\n",
        "print('test accuracy = ', accuracy_score(y_true=y_test, y_pred=y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train accuracy =  0.9301911544227887\n",
            "test accuracy =  0.8545727136431784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYCMTU_JW4kP",
        "outputId": "251824c1-e732-4aa2-f251-1f84b67c014b"
      },
      "source": [
        "lr.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9452773613193404"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg3Pvmj-I4eO"
      },
      "source": [
        "55. 混同行列の作成\n",
        "\n",
        "52で学習したロジスティック回帰モデルの混同行列（confusion matrix）を，学習データおよび評価データ上で作成せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu1oBYaDIJWT",
        "outputId": "c6a3fc38-5e62-4728-e068-6684039a7134"
      },
      "source": [
        "print('train:\\n',confusion_matrix(y_train, y_train_pred))\n",
        "print('test:\\n',confusion_matrix(y_test, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train:\n",
            " [[4457   51    3   35]\n",
            " [  21 4153    0    4]\n",
            " [  80  127  528    4]\n",
            " [ 152  105    2  950]]\n",
            "test:\n",
            " [[534  20   2  10]\n",
            " [ 10 520   0   1]\n",
            " [ 17  25  39   2]\n",
            " [ 42  33   1  78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yn605ALJAI_"
      },
      "source": [
        "56. 適合率，再現率，F1スコアの計測\n",
        "\n",
        "52で学習したロジスティック回帰モデルの適合率，再現率，F1スコアを，評価データ上で計測せよ．カテゴリごとに適合率，再現率，F1スコアを求め，カテゴリごとの性能をマイクロ平均（micro-average）とマクロ平均（macro-average）で統合せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI83kGNPKhsH",
        "outputId": "c5b837d2-dd49-40a4-ab42-ca4a41a9d56e"
      },
      "source": [
        "precision_micro = precision_score(y_test, y_test_pred, average='micro')\n",
        "precision_macro = precision_score(y_test, y_test_pred, average='macro')\n",
        "recall_micro = recall_score(y_test, y_test_pred, average='micro')\n",
        "recall_macro = recall_score(y_test, y_test_pred, average='macro')\n",
        "f1_micro = f1_score(y_test, y_test_pred, average='micro')\n",
        "f1_macro = f1_score(y_test, y_test_pred, average='macro')\n",
        "print('precision_micro', precision_micro, '\\nprecision_macro',precision_macro,\n",
        "      '\\nrecall_micro', recall_micro, '\\nrecall_macro', recall_macro,\n",
        "      '\\nf1_micro', f1_micro, '\\nf1_macro', f1_macro)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision_micro 0.8778110944527736 \n",
            "precision_macro 0.8852129106022683 \n",
            "recall_micro 0.8778110944527736 \n",
            "recall_macro 0.7247800728017938 \n",
            "f1_micro 0.8778110944527736 \n",
            "f1_macro 0.7738763097077297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQfqdkzHJALe"
      },
      "source": [
        "57. 特徴量の重みの確認\n",
        "\n",
        "52で学習したロジスティック回帰モデルの中で，重みの高い特徴量トップ10と，重みの低い特徴量トップ10を確認せよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6Sr6vBWOE_j",
        "outputId": "bc9b16c4-56b9-49e7-d312-12f7e41f01f5"
      },
      "source": [
        "lr_coef = pd.DataFrame(lr.coef_, columns=vectorizer.get_feature_names_out(), index=lr.classes_).T\n",
        "for i in lr_coef.columns:\n",
        "  print(lr_coef[[i]].nlargest(10, i))\n",
        "  print(lr_coef[[i]].nsmallest(10, i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                b\n",
            "fed      3.541107\n",
            "china    3.410867\n",
            "bank     3.286999\n",
            "ecb      3.092041\n",
            "stocks   2.988420\n",
            "euro     2.732873\n",
            "oil      2.730010\n",
            "update   2.705977\n",
            "ukraine  2.528271\n",
            "profit   2.503273\n",
            "               b\n",
            "and    -2.630520\n",
            "the    -2.080454\n",
            "her    -1.971904\n",
            "ebola  -1.959920\n",
            "she    -1.861273\n",
            "google -1.780204\n",
            "study  -1.763494\n",
            "star   -1.745120\n",
            "apple  -1.720509\n",
            "video  -1.639635\n",
            "                   e\n",
            "kardashian  3.277306\n",
            "chris       2.820279\n",
            "star        2.791977\n",
            "miley       2.487801\n",
            "she         2.469533\n",
            "cyrus       2.443998\n",
            "her         2.434463\n",
            "kim         2.412986\n",
            "paul        2.317321\n",
            "film        2.253812\n",
            "                 e\n",
            "update   -3.396209\n",
            "us       -3.226309\n",
            "google   -2.914981\n",
            "china    -2.422805\n",
            "facebook -2.379969\n",
            "ceo      -2.173377\n",
            "says     -2.150249\n",
            "gm       -2.134121\n",
            "apple    -2.118465\n",
            "billion  -2.078436\n",
            "                   m\n",
            "ebola       4.755472\n",
            "cancer      4.107791\n",
            "study       3.868117\n",
            "fda         3.543722\n",
            "drug        3.512737\n",
            "mers        3.159343\n",
            "health      2.740370\n",
            "cases       2.543054\n",
            "virus       2.402698\n",
            "cigarettes  2.198758\n",
            "                 m\n",
            "facebook -1.088242\n",
            "gm       -1.080165\n",
            "google   -0.953401\n",
            "apple    -0.949442\n",
            "twitter  -0.897456\n",
            "climate  -0.891909\n",
            "ceo      -0.887972\n",
            "sales    -0.802446\n",
            "bank     -0.785755\n",
            "at       -0.780270\n",
            "                  t\n",
            "google     5.648586\n",
            "facebook   5.075422\n",
            "apple      4.788416\n",
            "climate    3.950499\n",
            "microsoft  3.813455\n",
            "gm         3.256031\n",
            "fcc        2.627394\n",
            "comcast    2.600662\n",
            "mobile     2.599964\n",
            "nasa       2.471228\n",
            "                   t\n",
            "stocks     -1.434643\n",
            "fed        -1.158464\n",
            "drug       -1.089061\n",
            "cancer     -1.071793\n",
            "day        -1.054297\n",
            "shares     -0.989733\n",
            "ecb        -0.980902\n",
            "ebola      -0.946603\n",
            "her        -0.938612\n",
            "kardashian -0.937675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81VCCwd-JAN6"
      },
      "source": [
        "58. 正則化パラメータの変更\n",
        "\n",
        "ロジスティック回帰モデルを学習するとき，正則化パラメータを調整することで，学習時の過学習（overfitting）の度合いを制御できる．異なる正則化パラメータでロジスティック回帰モデルを学習し，学習データ，検証データ，および評価データ上の正解率を求めよ．実験の結果は，正則化パラメータを横軸，正解率を縦軸としたグラフにまとめよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gwag_UO2d_G",
        "outputId": "0d8db887-94c3-4f2a-f5fa-cefb65715567"
      },
      "source": [
        "C = [10**i for i in range(-7,2)]\n",
        "df_score = pd.DataFrame()\n",
        "for c in C:\n",
        "  lr = LogisticRegression(random_state=0, C=c)\n",
        "  lr.fit(X_train, y_train)\n",
        "  tmp = pd.DataFrame([c, lr.score(X_train, y_train), lr.score(X_valid, y_valid), lr.score(X_test, y_test)]).T\n",
        "  df_score = pd.concat([df_score,tmp])\n",
        "df_score.columns = ['C','train','valid','test']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "KOuTH9sgXFv_",
        "outputId": "9f30389d-e64e-415d-8624-ede0c225c780"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in ['train', 'valid', 'test']:\n",
        "  plt.plot(df_score['C'], df_score[i])\n",
        "\n",
        "plt.legend(['train', 'valid', 'test'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "yPf50_FvlCmk",
        "outputId": "bd9d3b5d-b604-4b07-c2d2-6544c531d76b"
      },
      "source": [
        "df_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C</th>\n",
              "      <th>train</th>\n",
              "      <th>valid</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e-07</td>\n",
              "      <td>0.425975</td>\n",
              "      <td>0.386057</td>\n",
              "      <td>0.424288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e-06</td>\n",
              "      <td>0.425975</td>\n",
              "      <td>0.386057</td>\n",
              "      <td>0.424288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e-05</td>\n",
              "      <td>0.425975</td>\n",
              "      <td>0.386057</td>\n",
              "      <td>0.424288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e-04</td>\n",
              "      <td>0.425975</td>\n",
              "      <td>0.386057</td>\n",
              "      <td>0.424288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e-03</td>\n",
              "      <td>0.428130</td>\n",
              "      <td>0.387556</td>\n",
              "      <td>0.425037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>0.751312</td>\n",
              "      <td>0.734633</td>\n",
              "      <td>0.751124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e-01</td>\n",
              "      <td>0.791885</td>\n",
              "      <td>0.776612</td>\n",
              "      <td>0.790105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.945277</td>\n",
              "      <td>0.885307</td>\n",
              "      <td>0.877811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e+01</td>\n",
              "      <td>0.998407</td>\n",
              "      <td>0.908546</td>\n",
              "      <td>0.913043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              C     train     valid      test\n",
              "0  1.000000e-07  0.425975  0.386057  0.424288\n",
              "0  1.000000e-06  0.425975  0.386057  0.424288\n",
              "0  1.000000e-05  0.425975  0.386057  0.424288\n",
              "0  1.000000e-04  0.425975  0.386057  0.424288\n",
              "0  1.000000e-03  0.428130  0.387556  0.425037\n",
              "0  1.000000e-02  0.751312  0.734633  0.751124\n",
              "0  1.000000e-01  0.791885  0.776612  0.790105\n",
              "0  1.000000e+00  0.945277  0.885307  0.877811\n",
              "0  1.000000e+01  0.998407  0.908546  0.913043"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_G829_aJAQp"
      },
      "source": [
        "59. ハイパーパラメータの探索\n",
        "\n",
        "学習アルゴリズムや学習パラメータを変えながら，カテゴリ分類モデルを学習せよ．検証データ上の正解率が最も高くなる学習アルゴリズム・パラメータを求めよ．また，その学習アルゴリズム・パラメータを用いたときの評価データ上の正解率を求めよ．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL-TRwGdA_tY",
        "outputId": "445b9530-9953-44f3-d198-5aec65ffc174"
      },
      "source": [
        "!pip install optuna\n",
        "!pip install lightgbm==3.3.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 308 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.27)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.5-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 35.8 MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "  Downloading cliff-3.10.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 59.7 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.3.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=fbb91f5a31de4b89371731e7ac9d1975dbd28643003eccb7c83fceefa6bcaa59\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.5 autopage-0.4.0 cliff-3.10.0 cmaes-0.8.2 cmd2-2.3.3 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.0 pyperclip-1.8.2 stevedore-3.5.0\n",
            "Collecting lightgbm==3.3.1\n",
            "  Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.3.1) (0.37.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.3.1) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.3.1) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.3.1) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.3.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.3.1) (3.0.0)\n",
            "Installing collected packages: lightgbm\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed lightgbm-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWI8Xn4aAbU7",
        "outputId": "92f27136-42f8-45ca-87d6-491d3ebcd1b4"
      },
      "source": [
        "# high parameter for logistical regression\n",
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    C = trial.suggest_loguniform(\"C\", 1e-7, 10.0)\n",
        "    solver = trial.suggest_categorical(\"solver\", (\"lbfgs\", \"saga\"))\n",
        "\n",
        "    clf = LogisticRegression(C=C, solver=solver)\n",
        "    clf.fit(X_train, y_train)\n",
        "    val_accuracy = clf.score(X_test, y_test)\n",
        "\n",
        "    return val_accuracy\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2021-12-09 12:44:01,346]\u001b[0m A new study created in memory with name: no-name-145ee62a-c4d5-4d2f-85e6-db14beba8b36\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:04,261]\u001b[0m Trial 0 finished with value: 0.424287856071964 and parameters: {'C': 2.7282757687721904e-05, 'solver': 'saga'}. Best is trial 0 with value: 0.424287856071964.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:05,189]\u001b[0m Trial 1 finished with value: 0.424287856071964 and parameters: {'C': 5.181521222762027e-07, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.424287856071964.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:08,046]\u001b[0m Trial 2 finished with value: 0.8628185907046477 and parameters: {'C': 0.6967438293117091, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.8628185907046477.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:08,502]\u001b[0m Trial 3 finished with value: 0.6394302848575713 and parameters: {'C': 0.00442971471328831, 'solver': 'lbfgs'}. Best is trial 2 with value: 0.8628185907046477.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "\u001b[32m[I 2021-12-09 12:44:11,266]\u001b[0m Trial 4 finished with value: 0.9100449775112444 and parameters: {'C': 7.483344247287183, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.9100449775112444.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:11,578]\u001b[0m Trial 5 finished with value: 0.43553223388305845 and parameters: {'C': 0.0013771002001181207, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.9100449775112444.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:12,153]\u001b[0m Trial 6 finished with value: 0.424287856071964 and parameters: {'C': 1.5641130339239284e-05, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.9100449775112444.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:14,472]\u001b[0m Trial 7 finished with value: 0.8575712143928036 and parameters: {'C': 0.5720725858681336, 'solver': 'lbfgs'}. Best is trial 4 with value: 0.9100449775112444.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n",
            "\u001b[32m[I 2021-12-09 12:44:21,464]\u001b[0m Trial 8 finished with value: 0.424287856071964 and parameters: {'C': 3.4030861535154947e-06, 'solver': 'saga'}. Best is trial 4 with value: 0.9100449775112444.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:24,847]\u001b[0m Trial 9 finished with value: 0.424287856071964 and parameters: {'C': 3.144763054776829e-05, 'solver': 'saga'}. Best is trial 4 with value: 0.9100449775112444.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "\u001b[32m[I 2021-12-09 12:44:27,660]\u001b[0m Trial 10 finished with value: 0.9107946026986506 and parameters: {'C': 7.610748552711928, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.9107946026986506.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "\u001b[32m[I 2021-12-09 12:44:30,312]\u001b[0m Trial 11 finished with value: 0.9107946026986506 and parameters: {'C': 9.23825654588097, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.9107946026986506.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:31,482]\u001b[0m Trial 12 finished with value: 0.7901049475262368 and parameters: {'C': 0.09946916799534682, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.9107946026986506.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "\u001b[32m[I 2021-12-09 12:44:34,265]\u001b[0m Trial 13 finished with value: 0.9107946026986506 and parameters: {'C': 9.801220495148993, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.9107946026986506.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:34,888]\u001b[0m Trial 14 finished with value: 0.7691154422788605 and parameters: {'C': 0.019275018253580054, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.9107946026986506.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:35,165]\u001b[0m Trial 15 finished with value: 0.8575712143928036 and parameters: {'C': 0.6022049746335099, 'solver': 'saga'}. Best is trial 10 with value: 0.9107946026986506.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:35,838]\u001b[0m Trial 16 finished with value: 0.7811094452773614 and parameters: {'C': 0.04358860780026323, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.9107946026986506.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:36,140]\u001b[0m Trial 17 finished with value: 0.424287856071964 and parameters: {'C': 0.0002762395169010748, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.9107946026986506.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:36,441]\u001b[0m Trial 18 finished with value: 0.9017991004497751 and parameters: {'C': 2.312922355883414, 'solver': 'saga'}. Best is trial 10 with value: 0.9107946026986506.\u001b[0m\n",
            "\u001b[32m[I 2021-12-09 12:44:37,555]\u001b[0m Trial 19 finished with value: 0.424287856071964 and parameters: {'C': 1.0684287606616866e-07, 'solver': 'lbfgs'}. Best is trial 10 with value: 0.9107946026986506.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "op5APBqYJLXA",
        "outputId": "4c1235a6-2e90-4743-9456-f2cce5502ade"
      },
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "df_X_train = pd.DataFrame(X_train.toarray())\n",
        "for col in df_X_train.columns:\n",
        "  df_X_train[col] = df_X_train[col].astype('float')\n",
        "\n",
        "dtrain = lgb.Dataset(df_X_train, label=y_train)\n",
        "dval = lgb.Dataset(pd.DataFrame(X_valid.toarray()), label=y_valid)\n",
        "\n",
        "param = {'objective': 'multiclass', 'num_class': 4}\n",
        "\n",
        "num_round = 10\n",
        "bst = lgb.train(param, dtrain, num_round, valid_sets=[dval])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-1d8aef318451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnum_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2603\u001b[0m                 )\n\u001b[1;32m   2604\u001b[0m             \u001b[0;31m# construct booster object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2605\u001b[0;31m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2606\u001b[0m             \u001b[0;31m# copy the parameters from train_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2607\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m   1820\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m   1555\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Cannot initialize Dataset from {type(data).__name__}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label should not be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mset_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m   2161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2163\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_to_1d_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_label_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# original values can be modified at cpp side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mlist_to_1d_numpy\u001b[0;34m(data, dtype, name)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd_Series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_get_bad_pandas_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Series.dtypes must be int, float or bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# SparseArray should be supported as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Series.dtypes must be int, float or bool"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWhB7SObTWK1",
        "outputId": "9041f512-2250-4e6c-dcde-d6dac6749e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10672 entries, 0 to 10671\n",
            "Columns: 14039 entries, 0 to 14038\n",
            "dtypes: float64(14039)\n",
            "memory usage: 1.1 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSYhavU0f_WF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "6fc5725e-01aa-4ed0-f3ea-7fa9c470e607"
      },
      "source": [
        "pd.DataFrame(X_train.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>13999</th>\n",
              "      <th>14000</th>\n",
              "      <th>14001</th>\n",
              "      <th>14002</th>\n",
              "      <th>14003</th>\n",
              "      <th>14004</th>\n",
              "      <th>14005</th>\n",
              "      <th>14006</th>\n",
              "      <th>14007</th>\n",
              "      <th>14008</th>\n",
              "      <th>14009</th>\n",
              "      <th>14010</th>\n",
              "      <th>14011</th>\n",
              "      <th>14012</th>\n",
              "      <th>14013</th>\n",
              "      <th>14014</th>\n",
              "      <th>14015</th>\n",
              "      <th>14016</th>\n",
              "      <th>14017</th>\n",
              "      <th>14018</th>\n",
              "      <th>14019</th>\n",
              "      <th>14020</th>\n",
              "      <th>14021</th>\n",
              "      <th>14022</th>\n",
              "      <th>14023</th>\n",
              "      <th>14024</th>\n",
              "      <th>14025</th>\n",
              "      <th>14026</th>\n",
              "      <th>14027</th>\n",
              "      <th>14028</th>\n",
              "      <th>14029</th>\n",
              "      <th>14030</th>\n",
              "      <th>14031</th>\n",
              "      <th>14032</th>\n",
              "      <th>14033</th>\n",
              "      <th>14034</th>\n",
              "      <th>14035</th>\n",
              "      <th>14036</th>\n",
              "      <th>14037</th>\n",
              "      <th>14038</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10667</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10668</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10669</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10670</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10671</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10672 rows × 14039 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0      1      2      3      4      ...  14034  14035  14036  14037  14038\n",
              "0        0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "1        0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "2        0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "3        0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "4        0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "...      ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
              "10667    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "10668    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "10669    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "10670    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "10671    0.0    0.0    0.0    0.0    0.0  ...    0.0    0.0    0.0    0.0    0.0\n",
              "\n",
              "[10672 rows x 14039 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgGRh439ghwR"
      },
      "source": [
        "df = pd.DataFrame(X_train.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4vAuy3GgokM",
        "outputId": "c2bef236-6fe6-49b7-85da-2ad0f84cdc18"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b    4548\n",
              "e    4206\n",
              "t    1221\n",
              "m     697\n",
              "Name: CATEGORY, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2JPa5bEgYRS",
        "outputId": "b10c6fbc-6727-4cd9-b658-030190614c0f"
      },
      "source": [
        "model = lgb.LGBMClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "print('train accuracy = ', accuracy_score(y_true=y_train, y_pred=y_train_pred))\n",
        "print('test accuracy = ', accuracy_score(y_true=y_test, y_pred=y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train accuracy =  0.9301911544227887\n",
            "test accuracy =  0.8545727136431784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYQRullzk7Xv"
      },
      "source": [
        "import numpy as np\n",
        "import optuna.integration.lightgbm as lgb\n",
        "\n",
        "from lightgbm import early_stopping\n",
        "from lightgbm import log_evaluation\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "dtrain = lgb.Dataset(pd.DataFrame(X_train.toarray()), label=y_train)\n",
        "dval = lgb.Dataset(pd.DataFrame(X_valid.toarray()), label=y_valid)\n",
        "\n",
        "params = {\n",
        "    \"objective\": \"multiclass\",\n",
        "    'num_class': 4,\n",
        "    # \"metric\": \"binary_logloss\",\n",
        "    \"verbosity\": -1,\n",
        "    \"boosting_type\": \"gbdt\",\n",
        "}\n",
        "\n",
        "model = lgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    valid_sets=[ dval],\n",
        "    # callbacks=[early_stopping(100), log_evaluation(100)],\n",
        ")\n",
        "\n",
        "prediction = np.rint(model.predict(X_valid, num_iteration=model.best_iteration))\n",
        "accuracy = accuracy_score(val_y, prediction)\n",
        "\n",
        "best_params = model.params\n",
        "print(\"Best params:\", best_params)\n",
        "print(\"  Accuracy = {}\".format(accuracy))\n",
        "print(\"  Params: \")\n",
        "for key, value in best_params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWn0cuvKXwJp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}